{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatCohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MCQGen\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatCohere` was deprecated in LangChain 0.0.30 and will be removed in 0.2.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import ChatCohere`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "llm=ChatCohere(cohere_api_key=os.getenv(\"COHERE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere\n",
    "from langchain.chains import LLMChain,SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ generator. For  {subject} students, Generate {number} multiple choice questions of {difficulty} difficulty \n",
    "Make sure the quetions are not repeated and all the questions must be from the given text. Make sure to format your response in given\\\n",
    "format: {responsejson}. Donot use any other words or anything like 'Here are ....' that might make difficult to extract quiz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(input_variables=['text','subject','number','difficulty','responsejson'],template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MCQGen\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "quiz_chain=LLMChain(llm=llm,prompt=prompt,output_key=\"quiz\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON={\n",
    "    1:{\n",
    "        'question':'question',\n",
    "        'options':{\n",
    "            'a':'choice1',\n",
    "            'b':'choice2',\n",
    "            'c':'choice3',\n",
    "            'd':'choice4'\n",
    "        },\n",
    "        'answer':'correct option'\n",
    "    },\n",
    "    2:{\n",
    "        'question':'question',\n",
    "        'options':{\n",
    "            'a':'choice1',\n",
    "            'b':'choice2',\n",
    "            'c':'choice3',\n",
    "            'd':'choice4'\n",
    "        },\n",
    "        'answer':'correct option'\n",
    "    },\n",
    "    3:{\n",
    "        'question':'question',\n",
    "        'options':{\n",
    "            'a':'choice1',\n",
    "            'b':'choice2',\n",
    "            'c':'choice3',\n",
    "            'd':'choice4'\n",
    "        },\n",
    "        'answer':'correct option'\n",
    "    },\n",
    "    4:{\n",
    "        'question':'question',\n",
    "        'options':{\n",
    "            'a':'choice1',\n",
    "            'b':'choice2',\n",
    "            'c':'choice3',\n",
    "            'd':'choice4'\n",
    "        },\n",
    "        'answer':'correct option'\n",
    "    },\n",
    "    5:{\n",
    "        'question':'question',\n",
    "        'options':{\n",
    "            'a':'choice1',\n",
    "            'b':'choice2',\n",
    "            'c':'choice3',\n",
    "            'd':'choice4'\n",
    "        },\n",
    "        'answer':'correct option'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. For a given mcq quiz for {subject} students, you need to evaluate the complexity of \\\n",
    "    problem and provide a complexity analysis of the quiz in 50 words. If the quiz is too difficult or too easy compared to congnitive \\\n",
    "    ability of students, you can change the difficulty to match the cognitive ability of students. \n",
    "    The Quiz:\n",
    "    {quiz}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=['subject','quiz'],template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm,prompt=quiz_evaluation_prompt,output_key='review',verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain,review_chain],input_variables=['text','subject','number','difficulty','responsejson'],output_variables=['quiz','review'],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}, \"2\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}, \"3\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}, \"4\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}, \"5\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_to_json=json.dumps(RESPONSE_JSON)\n",
    "dict_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"D:/MCQGen/data.txt\"\n",
    "with open(filepath,'r') as file:\n",
    "    TEXT=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5\n",
    "SUBJECT='machine learning'\n",
    "DIFFICULTY='hard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MCQGen\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:A transformer is a deep learning architecture developed by Google and based on the multi-head attention mechanism, proposed in a 2017 paper \"Attention Is All You Need\".[1] Text is converted to numerical representations called tokens, and each token is converted into a vector via looking up from a word embedding table.[1] At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism allowing the signal for key tokens to be amplified and less important tokens to be diminished. The transformer paper, published in 2017, is based on the softmax-based attention mechanism proposed by Bahdanau et. al. in 2014 for machine translation,[2][3] and the Fast Weight Controller, similar to a transformer, proposed in 1992.[4][5][6]\n",
      "\n",
      "Transformers have the advantage of having no recurrent units, and thus requires less training time than previous recurrent neural architectures, such as long short-term memory (LSTM),[7] and its later variation has been prevalently adopted for training large language models (LLM) on large (language) datasets, such as the Wikipedia corpus and Common Crawl.[8]\n",
      "\n",
      "This architecture is now used not only in natural language processing and computer vision,[9] but also in audio[10] and multi-modal processing. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs)[11] and BERT[12] (Bidirectional Encoder Representations from Transformers).\n",
      "\n",
      "You are an expert MCQ generator. For  machine learning students, Generate 5 multiple choice questions of hard difficulty \n",
      "Make sure the quetions are not repeated and all the questions must be from the given text. Make sure to format your response in givenformat: {\"1\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}, \"2\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}, \"3\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}, \"4\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}, \"5\": {\"question\": \"question\", \"options\": {\"a\": \"choice1\", \"b\": \"choice2\", \"c\": \"choice3\", \"d\": \"choice4\"}, \"answer\": \"correct option\"}}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. For a given mcq quiz for machine learning students, you need to evaluate the complexity of     problem and provide a complexity analysis of the quiz in 50 words. If the quiz is too difficult or too easy compared to congnitive     ability of students, you can change the difficulty to match the cognitive ability of students. \n",
      "    The Quiz:\n",
      "    {\"1\": {\"question\": \"What is the primary advantage of Transformers over recurrent neural architectures like LSTM?\", \"options\": {\"a\": \"They use a multi-layer perceptron for processing tokens.\", \"b\": \"They employ self-attention mechanisms for context understanding.\", \"c\": \"They do not rely on recurrent units, resulting in reduced training times.\", \"d\": \"They use a convolutional neural network for faster token processing.\"}, \"answer\": \"c\"}, \"2\": {\"question\": \"Which of the following best describes the input process for Transformers?\", \"options\": {\"a\": \"Text is converted to tokens, and each token is embedded into a vector space.\", \"b\": \"Text is processed as a whole, and then divided into token embeddings.\", \"c\": \"Text is first converted to an image, then tokenized and embedded.\", \"d\": \"Text is pre-processed using a recurrent neural network, then tokenized and embedded.\"}, \"answer\": \"a\"}, \"3\": {\"question\": \"The Transformer architecture is based on which of these attention mechanisms?\", \"options\": {\"a\": \"Hard attention\", \"b\": \"Soft attention\", \"c\": \"Softmax-based attention\", \"d\": \"Visual attention\"}, \"answer\": \"c\"}, \"4\": {\"question\": \"Which of the following is NOT a use case for Transformers?\", \"options\": {\"a\": \"Natural Language Processing\", \"b\": \"Audio processing and generation\", \"c\": \"Image classification and object detection\", \"d\": \"Multi-modal data understanding and generation\"}, \"answer\": \"c\"}, \"5\": {\"question\": \"What are two prominent pre-trained systems that utilize the Transformer architecture?\", \"options\": {\"a\": \"BERT and GPT\", \"b\": \"Fast Weight Controller and LSTM\", \"c\": \"Softmax and Attention Mechanism\", \"d\": \"Computer Vision and Natural Language Understanding\"}, \"answer\": \"a\"}}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=generate_evaluate_chain(\n",
    "    {\n",
    "    'text':TEXT,\n",
    "    'subject':SUBJECT,\n",
    "    'number':NUMBER,\n",
    "    'difficulty':DIFFICULTY,\n",
    "    'responsejson':dict_to_json,\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "quiz=response['quiz']\n",
    "quiz=ast.literal_eval(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_arr=[]\n",
    "for key,value in quiz.items():\n",
    "    mcq=value['question']\n",
    "    options='|'.join([\n",
    "        f\"{option}:{option_value}\" for option,option_value in value['options'].items()\n",
    "    ])\n",
    "    answers=value['answer']\n",
    "    my_arr.append({'question':mcq,'options':options,'answer':answers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is the primary advantage of Transformers over recurrent neural architectures like LSTM?',\n",
       "  'options': 'a:They use a multi-layer perceptron for processing tokens.|b:They employ self-attention mechanisms for context understanding.|c:They do not rely on recurrent units, resulting in reduced training times.|d:They use a convolutional neural network for faster token processing.',\n",
       "  'answer': 'c'},\n",
       " {'question': 'Which of the following best describes the input process for Transformers?',\n",
       "  'options': 'a:Text is converted to tokens, and each token is embedded into a vector space.|b:Text is processed as a whole, and then divided into token embeddings.|c:Text is first converted to an image, then tokenized and embedded.|d:Text is pre-processed using a recurrent neural network, then tokenized and embedded.',\n",
       "  'answer': 'a'},\n",
       " {'question': 'The Transformer architecture is based on which of these attention mechanisms?',\n",
       "  'options': 'a:Hard attention|b:Soft attention|c:Softmax-based attention|d:Visual attention',\n",
       "  'answer': 'c'},\n",
       " {'question': 'Which of the following is NOT a use case for Transformers?',\n",
       "  'options': 'a:Natural Language Processing|b:Audio processing and generation|c:Image classification and object detection|d:Multi-modal data understanding and generation',\n",
       "  'answer': 'c'},\n",
       " {'question': 'What are two prominent pre-trained systems that utilize the Transformer architecture?',\n",
       "  'options': 'a:BERT and GPT|b:Fast Weight Controller and LSTM|c:Softmax and Attention Mechanism|d:Computer Vision and Natural Language Understanding',\n",
       "  'answer': 'a'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "quiz_df=pd.DataFrame(my_arr)\n",
    "quiz_df.to_csv('quiz.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
